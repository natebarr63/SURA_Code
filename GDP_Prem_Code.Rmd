---
title: "GDP_Prem_Tests"
author: "Nathan Barretto"
date: "2024-05-19"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
#importing the two datasets: GDP data and Veronesi data 
proxy_data <- read_csv("data_policycle.csv")
gdp_data <- read_csv("USGDP.csv")
combined_data <- merge(proxy_data, gdp_data)

```



```{r}
#invert rows and columns for gdp dataset
#source: https://stackoverflow.com/questions/33643181/how-do-i-flip-rows-and-columns-in-r
gdp_data_2 <- data.frame(t(gdp_data[-1]))
colnames(gdp_data) <- gdp_data[, 1]
```

```{r}
#rename columns in proxy dataset

#first column name changed to year_month
colnames(proxy_data)[1] <- "quarter_year"

```

```{r}
#adjust column names in gdp dataset to get the names of the columns to be that 
#of the first row names

for (x in 3:38) {
  name <- gdp_data_2[1,x]
  name_string <- toString(name) 
  colnames(gdp_data_2)[x] <- name_string
}
```


```{r}
#Adjust column names in proxy and gdp data to accurately reflect measurements
colnames(proxy_data)[67] <- "DPRatio"
#one-year equity premium bound proposed by Ian Martin in 2017
colnames(proxy_data)[70] <- "EP_Bound"
colnames(proxy_data)[47] <- "IPO_Gross"
colnames(proxy_data)[75] <- "Price_Volatile_Stocks"
colnames(proxy_data)[69] <- "Surplus_Cons_Ratio"
colnames(proxy_data)[76] <- "Agreggate_Risk_Aversion"
colnames(proxy_data)[19] <- "Unemployment_Rate"
colnames(gdp_data_2)[5] <- "GDP"
```


```{r}
#delete row 1 of gdp_data with the old names
gdp_data_2 <- gdp_data_2[-c(1), ]

```

```{r}
#delete first 2 columns of gdp_data
#Blank cells
gdp_data_2 <- gdp_data_2[ -c(1,2) ]
```



```{r}
#split proxy_data by quarter and year

#quarter makers function
quarter_makers = function(mths){
 q1_Vector <- c(1, 2, 3)
 q2_Vector <- c(4, 5, 6)
 q3_Vector <- c(7, 8, 9)
 q4_Vector <- c(10, 11, 12)
 
 result <- c()
 
 for(i in 1:length(mths)){
  if (mths[i] %in% q1_Vector ){
    result[i] <- "Q1"
  }
  else if (mths[i] %in% q2_Vector ){
    result[i] <- "Q2"
  }
  else if (mths[i] %in% q3_Vector ){
    result[i] <- "Q3"
  }
   else {
    result[i] <- "Q4"
   }
 }
 
 return (result)
}

```



```{r}
#Generate split of quarter and years using quarter makers function
proxy_data$months = as.numeric(substr(as.character(proxy_data$quarter_year),5,6))
proxy_data$Year = as.numeric(substr(as.character(proxy_data$quarter_year),1,4))
proxy_data$Quarter = quarter_makers(proxy_data$months)
```

```{r}
#download hmisc package
install.packages("Hmisc")
install.packages("acepack")
```


```{r}
#Modify both datasets so they include the same quarters from 1960 - 2015
#results in same dimensions for statistical analysis later
proxy_data_mod_final <- proxy_data[-c(1: 395), ]
```


```{r}
#Modify both datasets so they include the same quarters from 1960 - 2015
#results in same dimensions for statistical analysis later
gdp_data_mod_final <- gdp_data_2[-c(1: 51), ]
```

```{r}
#Modify both datasets so they include the same quarters from 1960 - 2015
#results in same dimensions for statistical analysis later
gdp_data_mod_final <- gdp_data_mod_final[-c(225: 257), ]
```

```{r}
#Create geometric mean function to get geometric mean for quarters 
#for proxy_data
geom_mean = function(months){
  result <- c()
  i = 1
  while(i < length(months)) {
    total <- c()
    for (j in 0:2){
      len_total <- length(total)
      total[[len_total + 1]] <- as.numeric(months[i + j])
    }
    value = exp(mean(log(as.numeric(total))))
    len_result <- length(result)
    result[[len_result + 1]] <- value
    i = i + 3
  }
  return (as.numeric(result))
}

```

```{r}
#Create arithmetic mean function to get arithmetic mean for quarters 
#for proxy_data
#Will use this for proxy measures that have negative values
ari_mean = function(months){
  result <- c()
  i = 1
  while(i < length(months)) {
    total <- c()
    for (j in 0:2){
      len_total <- length(total)
      total[[len_total + 1]] <- as.numeric(months[i + j])
    }
    value = mean(as.numeric(total))
    len_result <- length(result)
    result[[len_result + 1]] <- value
    i = i + 3
  }
  return (as.numeric(result))
}

```






```{r}
#Since each measure in the proxy dataset has different missing values/ years with data filled in,
#I will split the large, combined dataset into smaller individual datasets by specific 
#proxy measure


#The 7 measures and their respective datasets:
  
#1. IPOGross (Gross Initial Public Offering),combined_data_IPO_Gross
#2. Aggregate , combined_data_Agreggate_Risk_Aversion
#3. DP (Dividend Price Ratio), combined_data_DPRatio
#4. EPBound (Equity Premium Bound), combined_data_EPBound
#5. SCR (Surplus Consumption Ratio), combined_data_surplus
#6. UNE (Unemployment Rate), combined_data_UNE
#7. PVS (Price of Volatile Stocks), combined_data_PVS
```



```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset with that measure for testing
combined_data_IPO_Gross <- data.frame(gdp_data_mod_final)
#Gross IPO By Quarter Added
combined_data_IPO_Gross$IPO_Gross = geom_mean(proxy_data_mod_final$IPO_Gross)
#remove original combined dataset
rm(combined_data)
#
```


```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset
#Aggregate Risk Aversion only has data from 1990 - 2010
#Start by changing gdp_data to only include this 
combined_data_Aggregate_Risk_Aversion <- data.frame(gdp_data_mod_final)
combined_data_Aggregate_Risk_Aversion <- combined_data_Aggregate_Risk_Aversion[-c(1: 120), ]
combined_data_Aggregate_Risk_Aversion <- combined_data_Aggregate_Risk_Aversion[-c(85: 104), ]
#Do the same for the proxy data 
proxy_data_cut <- data.frame(proxy_data_mod_final)
proxy_data_cut <- proxy_data_cut[-c(613: 672), ]
proxy_data_cut <- proxy_data_cut[-c(1: 360), ]
#Since aggregate risk aversion has negatives use arithmetic mean for quarter averages
#Aggregate Risk Aversion By Quarter Added
combined_data_Aggregate_Risk_Aversion$Aggregate_Risk_Aversion = ari_mean(proxy_data_cut$Agreggate_Risk_Aversion)
#
```


```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset with that measure for testing
combined_data_DPRatio <- data.frame(gdp_data_mod_final)
#DPRatio By Quarter Added
combined_data_DPRatio$DPRatio = geom_mean(proxy_data_mod_final$DPRatio)
```

```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset
#Equity Premium Bound only has data from 1996 - 2011
#Start by changing gdp_data to only include this 
combined_data_EPBound <- data.frame(gdp_data_mod_final)
combined_data_EPBound <- combined_data_EPBound[-c(1: 144), ]
combined_data_EPBound <- combined_data_EPBound[-c(65: 80), ]
#Do the same for the proxy data 
proxy_data_cut <- data.frame(proxy_data_mod_final)
proxy_data_cut <- proxy_data_cut[-c(625: 672), ]
proxy_data_cut <- proxy_data_cut[-c(1: 432), ]
#Equity Premium Bound By Quarter Added
combined_data_EPBound$EPBound = geom_mean(proxy_data_cut$EP_Bound)
#
```



```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset with that measure for testing
combined_data_surplus <- data.frame(gdp_data_mod_final)
#Surplus Consumption Ratio By Quarter Added
#negative values so use arithmetic mean
combined_data_surplus$SCR = ari_mean(proxy_data_mod_final$Surplus_Cons_Ratio)

```

```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset with that measure for testing
combined_data_UNE <- data.frame(gdp_data_mod_final)
#Unemployment Rate By Quarter Added
combined_data_UNE$UNE = geom_mean(proxy_data_mod_final$Unemployment_Rate)

```



```{r}
#Apply geom mean function to different proxy measures by quarter average and
#add them to new, cumulative dataset with that measure for testing
#PVS only has data from 1970 quarter 2, and is itself only available by quarter
combined_data_PVS <- data.frame(gdp_data_mod_final)
combined_data_PVS <- combined_data_PVS[-c(1: 41), ]
proxy_data_cut <- data.frame(proxy_data_mod_final)
proxy_data_cut <- proxy_data_cut[-c(1: 123), ]
#Run a for loop to keep every third row with the pvs data of the quarter in 
#the proxy dataset
 i = 3
 total <- c()
 while(i <= length(proxy_data_cut$Price_Volatile_Stocks)) {
    value = proxy_data_cut$Price_Volatile_Stocks[i]
    len_total <- length(total)
    total[[len_total + 1]] <- value
    i = i + 3
  }
#Price of Volatile Stock By Quarter Added
combined_data_PVS$PVS = total

```

```{r}
#All datasets now completed, can begin running tests
```



```{r}
#Start with an anova test for Gross IPO

#1: Anova test on the quarters to see if there is difference in the Gross IPO 
#by time in the year

IPO.aov <- aov(IPO_Gross ~ Quarter, data = combined_data_IPO_Gross)
# Summary
summary(IPO.aov)


```
```{r}
#P-value of 0.351. Indicates that there are no significant differences in the 
#mean gross ipo by quarter 
```



```{r}
#boxplots of the quarter ~ gross ipo relationship
boxplot(IPO_Gross~Quarter,data=combined_data_IPO_Gross, main="Gross IPO vs Yearly Quarter",
   xlab="Quarter", ylab="Gross IPO")
```